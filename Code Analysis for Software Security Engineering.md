# Code Analysis for Software Security Engineering
## Part 1: Code Review
### Code Review Strategy
#### Review Scope

>>> TODO: Talk about how Shane came up with checklist based on review of diagram and https://cwe.mitre.org/data/definitions/699.html

***
#### CWE Checklist
1) CWE-538: Insertion of Sensitive Information into Externally-Accessible File or Directory
2) CWE-532: Insertion of Sensitive Information into Log File
3) CWE-200: Exposure of Sensitive Information to an Unauthorized Actor
4) CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')
5) CWE-73: External Control of File Name or Path
6) CWE-126: Buffer Over-read
7) CWE-127: Buffer Under-read
8) CWE-125: Out-of-bounds Read
9) CWE-124: Buffer Underwrite ('Buffer Underflow')
10) CWE-349: Acceptance of Extraneous Untrusted Data With Trusted Data

>>>TODO: Shane add more details here 

***

#### Automated Tool Selection
1) SonarCloud
2) CodeQL
3) Fortify
4) Flaw Finder
   
>>> TODO: do we need to add why we picked what? maybe not?
   
#### What challenges did you expect before starting the code review?

>>> TODO:
>>> - Not familiar with C/Rust code

#### How did your code review strategy attempt to address the anticipated challenges?

>>> TODO: 

***
### Manual Code Review Findings

>>> TODO: 

***

### Automated Code Scan Findings
#### Automated #1 [SonarCloud](https://sonarcloud.io/)

One of the automated tools that has been used to scan the Suricata codebase has been SonarCloud. This particular automated code scanning tool was leveraged due to its availability for use with both public and open-source repositories from GitHub and other sources without need a of a subscription, easy integration into GitHub's code scanning functionality, and it's compatability with a variety of coding languages. The Suricata open-source software project includes multiple languages with its majority having been written in the C programming language and other significant shares being written in Rust, Python, and more. This versatility from the tool allowed for the spotting of issues from not just one specific code region or language comprising Suricata but the whole application. Upon review of the analysis results, it was found that many of the issues raised for the Suricata codebase pertained to issues of reliability and maintainability with 84 and 7,651 issues for the two categories respectively. For issues relating to security, which is the primary area of interest of the application for this course, there were a much more managable 24 issues raised. A link to the overall analysis report generated by SonarCloud is provided below. It is the security issues highlighted in the report which will be the primary talking point of the tool's findings.

[SonarCloud Analysis Output Link](https://sonarcloud.io/summary/overall?id=shellis0_suricata)

![image](https://github.com/UNO-CYBR-8420-Team1/CYBR8420-Suricata/blob/main/Code%20Analysis%20Brainstorm/SonarCloud%20Scan%20Reults%20Image.png)

As can be seen in an image listing the security issues provided from the SonarCloud analysis above, the 24 issues aligned with two distinct concerns with the first concern being found twice and the second concern being found in multiple instances of the codebase. Both of the topics of concern found within the security issues of the tool aligned with CWEs, both of which were not concerns identified within our initial CWE checklist.

The first concern discussing TOCTOU vulnerabilities aligned with CWE-367 and was found both times within a singular file, `src/conf-yaml-loader.c`. The general details of the CWE involve the software security weakness associated with the actions of checking and utilizing code and the periods of time between those events allowing for potential exploits to occur. This finding, more specifically the file for which the CWE was linked, was found to be a key area of focus for the code analysis as the weakness mentioned impacted the file responsible for loading and parsing the YAML configuration file used by Suricata. From previous project deliverables concerning use cases and misuse cases, assurance cases, and threat modeling the configuration component of Suricata, through its YAML file, was a recurring area of great importance as it is in charge of the setup and management of Suricata.

The second concern was identified across 22 security issues listed in the automated analysis spanning 22 separate C source code files. Each of the source files listed with the issues pertaining to this concern were files responsible for various alerts, logs, outputs, and utilities. This concern aligned with CWE-14 which is a weakness involving memory handling where the compiler chooses to optimize by not accessing memory rather than clearing it as specified by source code implementations. This weakness was also found to be important as another major component to Suricata's operation is its capactity to output information relating to information flowing across the network it is responsible for analyzing. It is able to do this, as has been learned through previous deliverables, in a variety of ways the most notable which being alerting and logging mechanisms for reporting on network activity. CWEs being listed in relation to these areas of code could be of importance as they too are a parts of prominant feature from the software.

Below is a table comprising the CWEs accquired from the SonarCloud tool alongside relevant information and affected files for further viewing. More detailed coverage of the respective CWEs from this tool beyond initial findings will be evaluated further within part two of the deliverable below. 

| **Security Issue** | **Severity** | **CWE Entry** | **Affected Files** |
| :--------------------------------------------------------- | :--: | :------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------- |
| Acessing files should not introduce TOCTOU vulnerabilities | High | [CWE-367: Time-of-check Time-of-use (TOCTOU) Race Condition](https://cwe.mitre.org/data/definitions/367) | [src/conf-yaml-loader.c](https://github.com/OISF/suricata/blob/master/src/conf-yaml-loader.c) |
| "memset" should not be used to delete sensitive data       | High | [CWE-14: Compiler Removal of Code to Clear Buffers](https://cwe.mitre.org/data/definitions/14.html)      | Some examples include: [src/alert-debuglog.c](https://github.com/OISF/suricata/blob/master/src/alert-debuglog.c), [src/log-tcp-data.c](https://github.com/OISF/suricata/blob/master/src/log-tcp-data.c), [src/output-json-file.c](https://github.com/OISF/suricata/blob/master/src/output-json-file.c), [src/util-logopenfile.c](https://github.com/OISF/suricata/blob/master/src/util-logopenfile.c) |

***

#### Automated #2 [GITHUB CodeQL](https://github.com/nsteck17/suricata/security/code-scanning)
Incase access to the Fork and scan results are limited, here's a PDF of the pages: 
- [Forked Suricata CodeQL PDF Page 1 of 2](https://github.com/UNO-CYBR-8420-Team1/CYBR8420-Suricata/blob/main/Code%20Analysis%20Brainstorm/CodeQL/Code%20scanning%20alerts%20%C2%B7%20nsteck17_suricata%20-%20P1.pdf)
- [Forked Suricata CodeQL PDF Page 2 of 2](https://github.com/UNO-CYBR-8420-Team1/CYBR8420-Suricata/blob/main/Code%20Analysis%20Brainstorm/CodeQL/Code%20scanning%20alerts%20%C2%B7%20nsteck17_suricata%20-%20P2.pdf)

![image](https://github.com/UNO-CYBR-8420-Team1/CYBR8420-Suricata/blob/main/Code%20Analysis%20Brainstorm/CodeQL/Screenshot%202024-12-07%20093638.png)

When creating the fork of Suricata, at first we struggled to get it working with CodeQL. We learned this is because the C code's build commands were not valid for the default CodeQL generated approach. After some trial and error (and educated review how CodeQL is setup/works) we finally saw that it is basaed on the .github/workflows/codeql.yml configuration and actually Suricata's source code actually already had an "advanced" setup [here](https://github.com/OISF/suricata/tree/master/.github/workflows) and finally we were able to get some results. 

Our initial checklist of CWEs identified CWE-22 and CWE-73 that was found in by results of the CodeQL scans, confirming our original thoughts. 
These both were associated to instances of "Uncontrolled data used in path expression" findings which there were three seperate entries for in the results set. 
![image](https://github.com/UNO-CYBR-8420-Team1/CYBR8420-Suricata/blob/main/Code%20Analysis%20Brainstorm/CodeQL/Screenshot%202024-12-07%20100156.png)
  
***

#### Automated #3 [Fortify Scan](https://github.com/UNO-CYBR-8420-Team1/CYBR8420-Suricata/blob/main/Code%20Analysis%20Brainstorm/UP%20Fortify%20Scan/suricata-version-Fortify_Security_Report.pdf)
![image](https://github.com/user-attachments/assets/052d0c3a-76dc-404b-b345-d74d219df8c1)

Nathan setup the Fortify scan using his work's (Union Pacific Railroad) provided Fortify utility scanning setup and default rules there (not on a GitHub intergration). He thought this would be a good "industry standard" approach as this is the same scan the rest of the code that runs in production goes through. Interestingly enough though it didn't actually scan all the C and Rust language files. It specifically captured the Python and other utility files (like Docker) where credentials are stored. So the results were not fully "inclusive" but it did give an interesting unique insight others may not be able to do.

Linked are a PDF of results, but it's important to note the scan also produced an "FPR" file that could be opened by Fortify workbench software. This makes it easeir to review the scan results in a more "user friendly" way with more details. This includes full code references and additional details not seen in the PDF output. 

#### Automated #4 Flaw Finder
>>> TODO: Grace ad more details here
***

***
## Part 2: Key Findings and Contributions
### Summary of Findings
>>> TODO:
We found common CWEs we expected to find in our checklist in our automated review:
1) CWE-134
>>> TODO: Grace
>>> Description,
>>> Found in files list/link,
>>> Analysis (Manual/Automated),
>>> Summary

***

2) CWE-22
>>> TODO: Matt
>>> Description,
>>> Found in files list/link,
>>> Analysis (Manual/Automated),
>>> Summary

***

3) CWE-73
>>> TODO: Ben
>>> Description,
>>> Found in files list/link,
>>> Analysis (Manual/Automated),
>>> Summary

***

4) CWE-95
#### Description
CWE-95 is defined as "Improper Neutralization of Directives in Dynamically Evaluated Code ('Eval Injection')". The code receives input from an upstream component, but it does not neutralize or incorrectly neutralizes code syntax before using the input in a dynamic evaluation call (e.g. "eval"). This may allow an attacker to execute arbitrary code, or at least modify what code can be executed.

#### Found in files
[LINE 259 of suricatasc.py](https://github.com/OISF/suricata/blob/master/python/suricata/sc/suricatasc.py#L259)
![image](https://github.com/user-attachments/assets/3510aa98-ecd7-4c16-a946-af609c372571)

#### Analysis
The Fortify Scan produced an FPR file with results that could be opened with it's Fortify Workbench Tool (and a summary PDF of results). We took a screenshot of the workbench utility reporting these results.
![image](https://github.com/UNO-CYBR-8420-Team1/CYBR8420-Suricata/blob/main/Code%20Analysis%20Brainstorm/UP%20Fortify%20Scan/1-critical-cwe95-cwe494-cwe094.PNG)

#### Summary
The automated fortify scan found this "Critical" issue of accepting user input. However I believe it is a false positive based on my review. Specifically the Fortify valunerability and CWE is indicating that user input is not sanitized before being executed. However, once you review the rest of the code starting with the function's name you see that it's interactive user input and more specitically the user is selecting from the list of options of commands. If the user is not allowed to enter anything like they, the vulnerability doesn't actually exist. 
![image](https://github.com/user-attachments/assets/db21cf22-8fea-4b59-b99d-34c0963fd4b5)

This is command-line interafaces so they're not able to "hack" the UI to enter invalid inputs another way. They only are given a set of options. 
![image](https://github.com/user-attachments/assets/a17c3f9c-a2d0-4fb3-8c42-2a23e963f0ea)

So based on my findings this is actually a false positive. I picked this example due to it being reported as critical, easily visiblity manually reviewed and actually a false positive. From expierence, this is a very REAL situation in industry. I (Nathan) work at Union Pacific Railroad and we use automated Fortify Scan results in our CI/CD pipeline for deployments to prevent code from going to prod if they have a critical vulnerability like this. So this could would not be "deployable" to production based on this without an exception. As well, when we delivered code to a client (the Norfolk Southern Railroad) we had to provide these Fortify scan results to prove none were in the deliverable executable code we provided. I find these scenarios a very good example of how automation isn't perfect. 

***

5) CWE-14 or CWE-367
>>> TODO: Shane 
>>> Description,
>>> Found in files list/link,
>>> Analysis (Manual/Automated),
>>> Summary

***
>>> TODO: Overall notes? maybe not?

### Ongoing Contributions
Team 1’s planned or ongoing contributions to the upstream OSS consist of keeping an eye on further developments of Suricata. There seems to be areas where the OSS can be improved such as a login function, integration with more SIEM like functions within the software if Suricata has aspirations of taking on such ideas to better sift through the data that it collects and permission based roles. As for code changes, our group is not as well versed on C and Rust code so the upkeep and contribution wouldn’t be much on the code change help. However, following up with recent implementations, updates, and understanding the news letters that are released help us stay more up to date and what to expect when reviewing OSS systems in an open source community. Suricata had a recent release and implementation as of October 1, 2024 and the community continues to support and fix vulnerabilities. As a group we would like to periodically stay on top with trends that we work with in our own environments and see possibly how they could contribute to other OSS systems.

### [GITHUB Project Board Link](https://github.com/orgs/UNO-CYBR-8420-Team1/projects/1/views/2)
### Individual Contributions
- Ben
  - TODO
- Grace
  - TODO
- Shane
  - TODO
- Matt
  - TODO
- Nathan
  - I started off by immediately attempting to fork the Suricata OOS GitHub codebase and get a quick setup of whatever running I could. However, I wasn't successful and didn't get back to it until after thankgiving when I could touchbase with Shane and Ben on 12/01/2024. Ben was attempting to get CodeQL running as well, so we prevent further duplication of efforts and I was able to get CodeQL setup working the next day and updated the team. I also leveraged my work's Fortify scanning installation at Union Pacific to attempt to scan the sourcecode however the tools were not configured for the C/Rust programming language and we got minimal results (we primarly focuses on Java and Javascript). In the group meeting I participated in our group discussion and the pressed to keep us organized and actionable by dividing up the assignments of individual deep dive of specific CWEs we found in our scan results so we can all make steps forward on individual contribution. I chose CWE-95 to do a deep dive on (with an example) based on my initial review of Fortify results and the related code. I am familiar with C++ from undergrad school years ago, but the C/Rust code took a bit to understand how to read. I also tried to put together the structure of the deliverables and first set of details for the team to try to build off of based on our team's initial agreement of how to layout details (adding notes to the reflection and other sections of this submission). 
    
***
### Team Reflection
This milestone proved to have some challenges in terms of working around holidays to meet with team members but we were able to overcome this by working through chat, Friday meetups, and discord calls. We were able to start out with an initial manual code analysis to get CWEs that may align with our OSS. We found that after doing a manual analysis and then pairing that with automatic analysis there were commonalities to help reinforce that this would be a great place to hone in on our CWEs. Our group chose to use several different automatic code analysis tools which ultimately worked in our favor to see what matched and if we were on the right track. The idea that we had some similar CWEs on different code tools didn’t necessarily mean those were all concrete and fit to our system but allowed us to take a closer look at the results that ultimately had ones that were true to our OSS. One of the tougher parts was combing through all of this data and making sure it was relevant to our system. In some cases it felt like there was a lot of noise being presented to us, however after utilizing multiple code analysis scans we could narrow the results down to our system needs. Additionally our group did a great job in our group discussion working around tasks and making clear expectations which allowed us to work cohesively for this section of milestone.
